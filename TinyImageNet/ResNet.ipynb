{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820f0a78-1abe-45a9-8965-99e4905c19d9",
   "metadata": {},
   "source": [
    "<h1>Tiny ImageNet</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6065f-28cd-4599-971e-ef1d3c0953ca",
   "metadata": {},
   "source": [
    "<h2>BEiT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686022f1-4ab1-4197-a8d2-f1e25f5fc385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Tiny ImageNet data loaders...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "        \n",
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 ** 2)\n",
    "\n",
    "def init_tiny_imagenet_data(data_dir, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir = os.path.join(data_dir, \"val/images\")\n",
    "\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Initialize data loaders\n",
    "print(\"Initializing Tiny ImageNet data loaders...\")\n",
    "tiny_imagenet_dir = \"./data/tiny-imagenet-200\"\n",
    "train_loader, val_loader = init_tiny_imagenet_data(tiny_imagenet_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae678798-23eb-43e4-94b7-0e0c6ca1c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model outputs\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "                # Use pooler_output or global average pooling for classification\n",
    "                teacher_logits = teacher_outputs.pooler_output\n",
    "\n",
    "            # Student model outputs\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss / len(train_loader), checkpoint_dir, prefix)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1fd6b8-3473-47fa-b4cd-9e068904865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_student_model(student_model, teacher_model, val_loader, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Load from checkpoint if specified\n",
    "    if checkpoint_dir and prefix:\n",
    "        print(f\"Searching for checkpoints in {checkpoint_dir}...\")\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Student model outputs\n",
    "            student_logits = student_model(images)\n",
    "            predictions = torch.argmax(student_logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc5546-7cfd-45ab-bc8a-a32f403d5542",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043ec9b9-e066-4045-8f04-a9a860660cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BEiT Teacher Model...\n",
      "Initializing ResNet Student Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet Student Model...\n",
      "Loading checkpoint from ./checkpoints/resnet_beit_epoch_4.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10960/3225173208.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 4.\n",
      "Training epoch 5/5...\n",
      "Epoch 5/5 Loss: 0.5559\n",
      "Checkpoint saved at ./checkpoints/resnet_beit_epoch_5.pt\n",
      "Training complete.\n",
      "Student Model Size: 43.03 MB\n",
      "Evaluating ResNet Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/resnet_beit_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10960/294627462.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.7150\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from transformers import BeitModel\n",
    "\n",
    "# Initialize BEiT Teacher Model\n",
    "print(\"Initializing BEiT Teacher Model...\")\n",
    "beit_teacher_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "# Initialize Student Model\n",
    "print(\"Initializing ResNet Student Model...\")\n",
    "num_classes = 200\n",
    "student_model = resnet18(pretrained=True)\n",
    "student_model.fc = torch.nn.Linear(student_model.fc.in_features, num_classes)\n",
    "\n",
    "prefix = \"resnet_beit_epoch_\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training\n",
    "print(\"Training ResNet Student Model...\")\n",
    "train_student_model(beit_teacher_model, student_model, train_loader, optimizer, 5, checkpoint_dir, prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating ResNet Student Model...\")\n",
    "evaluate_student_model(student_model, beit_teacher_model, val_loader, checkpoint_dir, prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4f145-a3f6-4c83-8866-5620667cd6c9",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc9284f-e188-4074-8b4d-839cee0d7e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BEiT Teacher Model...\n",
      "Initializing ResNet Student Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet Student Model...\n",
      "Loading checkpoint from ./checkpoints/resnet_beit_epoch_8.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5961/3225173208.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 8.\n",
      "Training epoch 9/10...\n",
      "Epoch 9/10 Loss: 0.1931\n",
      "Checkpoint saved at ./checkpoints/resnet_beit_epoch_9.pt\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 0.1573\n",
      "Checkpoint saved at ./checkpoints/resnet_beit_epoch_10.pt\n",
      "Training complete.\n",
      "Student Model Size: 43.03 MB\n",
      "Evaluating ResNet Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/resnet_beit_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5961/294627462.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating ResNet Student Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mevaluate_student_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeit_teacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m, in \u001b[0;36mevaluate_student_model\u001b[0;34m(student_model, teacher_model, val_loader, checkpoint_dir, prefix)\u001b[0m\n\u001b[1;32m     37\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(all_labels, all_predictions)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from transformers import BeitModel\n",
    "\n",
    "# Initialize BEiT Teacher Model\n",
    "print(\"Initializing BEiT Teacher Model...\")\n",
    "beit_teacher_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "# Initialize Student Model\n",
    "print(\"Initializing ResNet Student Model...\")\n",
    "num_classes = 200\n",
    "student_model = resnet18(pretrained=True)\n",
    "student_model.fc = torch.nn.Linear(student_model.fc.in_features, num_classes)\n",
    "\n",
    "prefix = \"resnet_beit_epoch_\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training\n",
    "print(\"Training ResNet Student Model...\")\n",
    "train_student_model(beit_teacher_model, student_model, train_loader, optimizer, 10, checkpoint_dir, prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating ResNet Student Model...\")\n",
    "evaluate_student_model(student_model, beit_teacher_model, val_loader, checkpoint_dir, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9d501a-06a4-4ff8-b4c6-f905cf54d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ResNet Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/resnet_beit_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5961/294627462.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.7011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Evaluation\n",
    "print(\"Evaluating ResNet Student Model...\")\n",
    "evaluate_student_model(student_model, beit_teacher_model, val_loader, checkpoint_dir, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd05622-8fee-463e-88b7-c33ed2a23bd9",
   "metadata": {},
   "source": [
    "<h2>DINO</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3df0b5-c103-4bf5-8c9c-c01a468101a9",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f6264e-d101-4619-a041-d38050e59875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Tiny ImageNet data loaders...\n",
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Initializing DINO Teacher Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yx3493/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet Student Model...\n",
      "Training Student Model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 166\u001b[0m\n\u001b[1;32m    163\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet_dino_epoch_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Student Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[43mtrain_student_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdino_teacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating Student Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m, in \u001b[0;36mtrain_student_model\u001b[0;34m(teacher_model, student_model, train_loader, optimizer, num_epochs, checkpoint_dir, prefix)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_student_model\u001b[39m(teacher_model, student_model, train_loader, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     74\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     teacher_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     77\u001b[0m     teacher_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, vit_b_16, ViT_B_16_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Utility Functions\n",
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 ** 2)\n",
    "\n",
    "\n",
    "def init_tiny_imagenet_data(data_dir, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((384, 384)),  # Match DINO's input size\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir = os.path.join(data_dir, \"val/images\")\n",
    "\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_student_model(teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        epoch_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher outputs\n",
    "            with torch.no_grad():\n",
    "                teacher_features = teacher_model(images)  # DINO ViT outputs [batch_size, hidden_dim]\n",
    "                teacher_logits = teacher_features.mean(dim=1)  # Global average pooling for class representation\n",
    "\n",
    "            # Student outputs\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Classification loss\n",
    "            loss = nn.CrossEntropyLoss()(student_logits, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "        print(f\"Epoch {epoch + 1} completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss / len(train_loader), checkpoint_dir, prefix)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_student_model(student_model, val_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    student_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = student_model(images)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Main Code\n",
    "print(\"Initializing Tiny ImageNet data loaders...\")\n",
    "tiny_imagenet_dir = \"./data/tiny-imagenet-200\"\n",
    "train_loader, val_loader = init_tiny_imagenet_data(tiny_imagenet_dir, batch_size=32)\n",
    "\n",
    "# Initialize Teacher and Student Models\n",
    "print(\"Initializing DINO Teacher Model...\")\n",
    "dino_weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "dino_teacher_model = vit_b_16(weights=dino_weights).eval()\n",
    "dino_teacher_model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "\n",
    "print(\"Initializing ResNet Student Model...\")\n",
    "student_model = resnet18(pretrained=True)\n",
    "student_model.fc = nn.Linear(student_model.fc.in_features, 200)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "prefix = \"resnet_dino_epoch_\"\n",
    "\n",
    "print(\"Training Student Model...\")\n",
    "train_student_model(dino_teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=checkpoint_dir, prefix=prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model(student_model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c26d1-455d-4088-9cb4-a1ff02fc48ab",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bfdb6-eeaf-42e3-9a15-564f8507e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Student Model...\")\n",
    "train_student_model(dino_teacher_model, student_model, train_loader, optimizer, num_epochs=10, checkpoint_dir=checkpoint_dir, prefix=prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model(student_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb95a7-016d-45cb-b01c-1ee34c5c7ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
