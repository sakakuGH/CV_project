{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b63511-8b88-4214-a9c9-2ac0083aeb01",
   "metadata": {},
   "source": [
    "<h1>TinyImageNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d9381b-761a-45f1-80b5-d28e30ea6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.models import vit_b_16\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import os\n",
    "\n",
    "class SimpleProjectionModel(nn.Module):\n",
    "    def __init__(self, vision_dim=256, teacher_output_dim=768):\n",
    "        super(SimpleProjectionModel, self).__init__()\n",
    "        # Vision encoder\n",
    "        self.vision_encoder = nn.Linear(teacher_output_dim, vision_dim)\n",
    "        # Logit scale for distillation\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * 0.07)\n",
    "\n",
    "    def forward(self, teacher_features):\n",
    "        # Normalize and project features\n",
    "        vision_proj = self.vision_encoder(teacher_features)\n",
    "        vision_proj = vision_proj / vision_proj.norm(dim=-1, keepdim=True)\n",
    "        # Compute logits (self-similarity or pairwise similarity)\n",
    "        logits = self.logit_scale.exp() * vision_proj @ vision_proj.t()\n",
    "        return logits\n",
    "\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024**2)\n",
    "    \n",
    "# Save checkpoint\n",
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Load checkpoint\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "\n",
    "# Initialize Tiny ImageNet dataset loaders\n",
    "def init_tiny_imagenet_data(data_dir, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "    val_dir = os.path.join(data_dir, \"val/images\")\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "    \n",
    "data_dir = \"./data/tiny-imagenet-200\"\n",
    "train_loader, val_loader = init_tiny_imagenet_data(data_dir, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250257b-91f1-4fb0-afd7-6c6d57beefd5",
   "metadata": {},
   "source": [
    "<h2>BEiT</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f38059-f7f6-4c61-ac14-c56c4a5ed877",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25fd83a-2033-4123-ab4a-9aec07f0f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student Model with Tiny ImageNet...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_epoch_5.pt...\n",
      "Resuming training from epoch 5.\n",
      "Student Model Size: 0.75 MB\n",
      "Training complete.\n",
      "Evaluating Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/models/beit/feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `BeitFeatureExtractor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "/tmp/ipykernel_5799/3927226470.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n",
      "/tmp/ipykernel_5799/889047548.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training logic\n",
    "def train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer, \n",
    "    num_epochs=10, temperature=2.0, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    epoch_times = []\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    student_model.train()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, _ in train_loader:\n",
    "            pil_images = [transforms.ToPILImage()(img) for img in images]\n",
    "\n",
    "            # Teacher model logits\n",
    "            with torch.no_grad():\n",
    "                teacher_inputs = teacher_processor(images=pil_images, return_tensors=\"pt\").to(device)\n",
    "                teacher_outputs = teacher_model(**teacher_inputs)\n",
    "                teacher_features = teacher_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(student_logits, torch.arange(len(student_logits)).to(device))\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f}\")\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.\")\n",
    "\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss, checkpoint_dir, prefix)\n",
    "            print(f\"saving checkpoint {prefix}...\")\n",
    "\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "    return epoch_times\n",
    "    \n",
    "# Evaluation logic\n",
    "def evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    if checkpoint_dir and prefix:\n",
    "        print(f\"Searching for checkpoints in {checkpoint_dir}...\")\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    student_model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in val_loader:\n",
    "            pil_images = [transforms.ToPILImage()(img) for img in images]\n",
    "\n",
    "            # Teacher model logits\n",
    "            teacher_inputs = teacher_processor(images=pil_images, return_tensors=\"pt\").to(device)\n",
    "            teacher_outputs = teacher_model(**teacher_inputs)\n",
    "            teacher_features = teacher_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "            predictions = torch.argmax(student_logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(torch.arange(len(predictions)).tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Initialize student model\n",
    "student_output_dim = 256\n",
    "beit_teacher_output_dim = 768\n",
    "student_model = SimpleProjectionModel(vision_dim=student_output_dim, teacher_output_dim=beit_teacher_output_dim)\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4)\n",
    "\n",
    "# Load teacher model\n",
    "from transformers import BeitModel, BeitFeatureExtractor\n",
    "teacher_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\").to('cuda')\n",
    "teacher_processor = BeitFeatureExtractor.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "# Train the student model - 5 epoches\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "prefix = \"simpleprojection_beit_epoch_\"\n",
    "\n",
    "print(\"Training Student Model with Tiny ImageNet...\")\n",
    "epoch_times = train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer, \n",
    "    num_epochs=5, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, \n",
    "    checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3e6e2-9359-45b0-a741-46dbc78010a2",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfbc322-16f5-42b4-833a-3d685cda9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student Model with Tiny ImageNet...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_epoch_5.pt...\n",
      "Resuming training from epoch 5.\n",
      "Training epoch 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5799/3927226470.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Loss: 0.0048\n",
      "Epoch 6 completed in 1756.25 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_epoch_6.pt\n",
      "saving checkpoint simpleprojection_beit_epoch_...\n",
      "Training epoch 7/10...\n",
      "Epoch 7/10 Loss: 0.0043\n",
      "Epoch 7 completed in 1761.47 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_epoch_7.pt\n",
      "saving checkpoint simpleprojection_beit_epoch_...\n",
      "Training epoch 8/10...\n",
      "Epoch 8/10 Loss: 0.0036\n",
      "Epoch 8 completed in 1758.53 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_epoch_8.pt\n",
      "saving checkpoint simpleprojection_beit_epoch_...\n",
      "Training epoch 9/10...\n",
      "Epoch 9/10 Loss: 0.0021\n",
      "Epoch 9 completed in 1793.96 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_epoch_9.pt\n",
      "saving checkpoint simpleprojection_beit_epoch_...\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 0.0012\n",
      "Epoch 10 completed in 1994.52 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_epoch_10.pt\n",
      "saving checkpoint simpleprojection_beit_epoch_...\n",
      "Student Model Size: 0.75 MB\n",
      "Training complete.\n",
      "Evaluating Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5799/889047548.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the student model - 10 epoches\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "prefix = \"simpleprojection_beit_epoch_\"\n",
    "\n",
    "print(\"Training Student Model with Tiny ImageNet...\")\n",
    "epoch_times = train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer, \n",
    "    num_epochs=10, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, \n",
    "    checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7bb55-3cde-4e9e-a941-67c9bad9fdb8",
   "metadata": {},
   "source": [
    "<h2>DINO</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d3cae-8428-4ab3-a7ef-815a57cfcb7c",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668ee4ae-8884-4ba8-aa68-8f85506652c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SimpleProjection Student Model...\n",
      "Loading DINO Teacher Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_epoch_2.pt...\n",
      "Resuming training from epoch 2.\n",
      "Training SimpleProjection Student Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_epoch_2.pt...\n",
      "Resuming training from epoch 2.\n",
      "Training epoch 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5476/4093043107.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 Loss: 0.1055\n",
      "Epoch 3 completed in 754.40 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_3.pt\n",
      "Training epoch 4/5...\n",
      "Epoch 4/5 Loss: 0.0555\n",
      "Epoch 4 completed in 797.98 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_4.pt\n",
      "Training epoch 5/5...\n",
      "Epoch 5/5 Loss: 0.0221\n",
      "Epoch 5 completed in 1226.30 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_5.pt\n",
      "Student Model Size: 0.75 MB\n",
      "Evaluating SimpleProjection Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5476/3977640529.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training function for the student model using DINO with SimpleProjection\n",
    "def train_student_model_dino(\n",
    "    teacher_model, student_model, train_loader, optimizer, \n",
    "    num_epochs=10, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    epoch_times = []\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    student_model.train()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Teacher model logits (DINO)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "                teacher_features = teacher_outputs[\"features\"].mean(dim=1)  # Global pooling\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "\n",
    "            # Compute distillation loss\n",
    "            loss = torch.nn.functional.cross_entropy(student_logits, torch.arange(len(student_logits)).to(device))\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f}\")\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.\")\n",
    "\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss, checkpoint_dir, prefix)\n",
    "            \n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "    return epoch_times\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_student_model_dino(student_model, teacher_model, val_loader, checkpoint_dir=None, prefix=None):\n",
    "    if checkpoint_dir and prefix:\n",
    "        print(f\"Searching for checkpoints in {checkpoint_dir}...\")\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    student_model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Teacher model logits (DINO)\n",
    "            teacher_outputs = teacher_model(images)\n",
    "            teacher_features = teacher_outputs[\"features\"].mean(dim=1)  # Global pooling\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "            predictions = torch.argmax(student_logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(torch.arange(len(predictions)).tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Main Code to Train and Evaluate\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize SimpleProjection Student Model\n",
    "print(\"Initializing SimpleProjection Student Model...\")\n",
    "student_model = SimpleProjectionModel(vision_dim=256, teacher_output_dim=768)\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4)\n",
    "\n",
    "# Load DINO Teacher Model\n",
    "print(\"Loading DINO Teacher Model...\")\n",
    "dino_teacher_model = vit_b_16(weights=\"IMAGENET1K_V1\").to('cuda')\n",
    "dino_teacher_model = create_feature_extractor(dino_teacher_model, return_nodes={\"encoder.layers\": \"features\"})\n",
    "\n",
    "# Load the latest checkpoint if it exists\n",
    "prefix = \"simpleprojection_dino_epoch_\"\n",
    "\n",
    "# Train the student model\n",
    "print(\"Training SimpleProjection Student Model...\")\n",
    "epoch_times = train_student_model_dino(\n",
    "    teacher_model=dino_teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=5,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating SimpleProjection Student Model...\")\n",
    "evaluate_student_model_dino(\n",
    "    student_model=student_model,\n",
    "    teacher_model=dino_teacher_model,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f363fe4-d3cc-48a4-a6de-6daad4fa53ae",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b08a0f6-a7cb-4cca-969e-31f657d96256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SimpleProjection Student Model...\n",
      "Loading DINO Teacher Model...\n",
      "Training SimpleProjection Student Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_epoch_5.pt...\n",
      "Resuming training from epoch 5.\n",
      "Training epoch 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/4093043107.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Loss: 0.0107\n",
      "Epoch 6 completed in 753.19 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_6.pt\n",
      "Training epoch 7/10...\n",
      "Epoch 7/10 Loss: 0.0034\n",
      "Epoch 7 completed in 392.35 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_7.pt\n",
      "Training epoch 8/10...\n",
      "Epoch 8/10 Loss: 0.0043\n",
      "Epoch 8 completed in 378.20 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_8.pt\n",
      "Training epoch 9/10...\n",
      "Epoch 9/10 Loss: 0.0035\n",
      "Epoch 9 completed in 375.94 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_9.pt\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 0.0023\n",
      "Epoch 10 completed in 380.70 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_epoch_10.pt\n",
      "Student Model Size: 0.75 MB\n",
      "Evaluating SimpleProjection Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/154558315.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the student model\n",
    "print(\"Training SimpleProjection Student Model...\")\n",
    "epoch_times = train_student_model_dino(\n",
    "    teacher_model=dino_teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating SimpleProjection Student Model...\")\n",
    "evaluate_student_model_dino(\n",
    "    student_model=student_model,\n",
    "    teacher_model=dino_teacher_model,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c23160-7e24-42eb-bc8a-dd253b3e1166",
   "metadata": {},
   "source": [
    "<h1>COCO</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bacc471-0cf5-4243-840c-784a0926e64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=17.66s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=2.40s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.models import vit_b_16\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# COCO dataset loader for classification\n",
    "class COCOClassification(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation_file, transform=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.transform = transform\n",
    "        self.image_ids = list(self.coco.imgToAnns.keys())\n",
    "        self.classes = list(self.coco.cats.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        annotations = self.coco.loadAnns(self.coco.getAnnIds(imgIds=image_id))\n",
    "\n",
    "        # Load image\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.root, image_info['file_name'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Create multi-label vector\n",
    "        labels = [0] * len(self.classes)\n",
    "        for ann in annotations:\n",
    "            category_idx = self.classes.index(ann['category_id'])\n",
    "            labels[category_idx] = 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Save checkpoint\n",
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Load checkpoint\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer=None):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            if 'epoch' in checkpoint:\n",
    "                start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "    \n",
    "# Initialize COCO dataset loaders\n",
    "def init_coco_data(data_dir, annotation_file, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset = COCOClassification(root=data_dir, annotation_file=annotation_file, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "# Student Model\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024**2)\n",
    "\n",
    "class SimpleProjectionModel(nn.Module):\n",
    "    def __init__(self, vision_dim=256, num_classes=80):\n",
    "        super(SimpleProjectionModel, self).__init__()\n",
    "        self.vision_encoder = nn.Linear(vision_dim, num_classes)\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * 0.07)\n",
    "\n",
    "    def forward(self, teacher_features):\n",
    "        logits = self.vision_encoder(teacher_features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Paths for COCO dataset\n",
    "train_data_dir = \"/home/yx3493/train2017/train2017\"\n",
    "train_annotation_file = \"/home/yx3493/annotations_trainval2017/annotations/instances_train2017.json\"\n",
    "val_data_dir = \"/home/yx3493/val2017/val2017\"\n",
    "val_annotation_file = \"/home/yx3493/annotations_trainval2017/annotations/instances_val2017.json\"\n",
    "\n",
    "train_loader = init_coco_data(train_data_dir, train_annotation_file, batch_size=8)\n",
    "val_loader = init_coco_data(val_data_dir, val_annotation_file, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420a4e0-d947-48f2-8626-379b635eb8f8",
   "metadata": {},
   "source": [
    "<h2>BEiT</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109933e9-5124-41a0-bb9b-f9afc15effe1",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fbf72a-f958-45c0-813d-c0b71604770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student Model with COCO dataset...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_coco_epoch_5.pt...\n",
      "Resuming training from epoch 5.\n",
      "Student Model Size: 0.23 MB\n",
      "Training complete.\n",
      "Evaluating Student Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_coco_epoch_5.pt...\n",
      "Resuming training from epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/models/beit/feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `BeitFeatureExtractor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "/tmp/ipykernel_6005/3200071927.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.2078\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Training logic\n",
    "def train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer,\n",
    "    num_epochs=10, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    # Multi-label loss\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            pil_images = [transforms.ToPILImage()(img) for img in images]\n",
    "\n",
    "            # Teacher model logits\n",
    "            with torch.no_grad():\n",
    "                teacher_inputs = teacher_processor(images=pil_images, return_tensors=\"pt\").to(device)\n",
    "                teacher_outputs = teacher_model(**teacher_inputs)\n",
    "                teacher_features = teacher_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "\n",
    "            # Compute loss (multi-label)\n",
    "            loss = criterion(student_logits, labels.to(device))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f}\")\n",
    "        save_checkpoint(student_model, optimizer, epoch, epoch_loss, checkpoint_dir, prefix)\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "\n",
    "# Evaluation logic\n",
    "def evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer=None)\n",
    "    student_model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            pil_images = [transforms.ToPILImage()(img) for img in images]\n",
    "\n",
    "            # Teacher model logits\n",
    "            teacher_inputs = teacher_processor(images=pil_images, return_tensors=\"pt\").to(device)\n",
    "            teacher_outputs = teacher_model(**teacher_inputs)\n",
    "            teacher_features = teacher_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "            predictions = torch.sigmoid(student_logits) > 0.5  # Multi-label thresholding\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute multi-label accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        [tuple(map(int, x)) for x in all_labels], [tuple(map(int, x)) for x in all_predictions]\n",
    "    )\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Initialize teacher and student models\n",
    "from transformers import BeitModel, BeitFeatureExtractor\n",
    "teacher_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\").to('cuda')\n",
    "teacher_processor = BeitFeatureExtractor.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "student_output_dim = 256\n",
    "beit_teacher_output_dim = 768\n",
    "num_classes = 80  # Number of COCO categories\n",
    "student_model = SimpleProjectionModel(vision_dim=beit_teacher_output_dim, num_classes=num_classes)\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4)\n",
    "\n",
    "# Train the student model\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "prefix = \"simpleprojection_beit_coco_epoch_\"\n",
    "\n",
    "print(\"Training Student Model with COCO dataset...\")\n",
    "train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer,\n",
    "    num_epochs=5, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee458a0-0386-48a5-b59d-f654cf8b8535",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f7b79f-e196-4e61-925c-bce2cacb9359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student Model with COCO dataset...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_coco_epoch_8.pt...\n",
      "Resuming training from epoch 8.\n",
      "Training epoch 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/models/beit/feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `BeitFeatureExtractor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "/tmp/ipykernel_11922/3200071927.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Loss: 1086.5213\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_coco_epoch_9.pt\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 1086.4022\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_beit_coco_epoch_10.pt\n",
      "Student Model Size: 0.23 MB\n",
      "Training complete.\n",
      "Evaluating Student Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_beit_coco_epoch_10.pt...\n",
      "Resuming training from epoch 10.\n",
      "Evaluation Accuracy: 0.2137\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Student Model with COCO dataset...\")\n",
    "train_student_model_beit(\n",
    "    teacher_model, teacher_processor, student_model, train_loader, optimizer,\n",
    "    num_epochs=10, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model_beit(\n",
    "    student_model, teacher_model, teacher_processor, val_loader, checkpoint_dir=checkpoint_dir, prefix=prefix\n",
    ")\n",
    "\n",
    "print(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a79ab-5637-4b8e-880d-0e490ddf70c7",
   "metadata": {},
   "source": [
    "<h2>DINO</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db9eaf-8543-4e36-b7dc-a14a4a979845",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1662586e-7cc6-447e-8ed7-8e72020505b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SimpleProjection Student Model...\n",
      "Loading DINO Teacher Model...\n",
      "Training SimpleProjection Student Model...\n",
      "Training epoch 1/5...\n",
      "Epoch 1/5 Loss: 1227.8319\n",
      "Epoch 1 completed in 606.73 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_1.pt\n",
      "Training epoch 2/5...\n",
      "Epoch 2/5 Loss: 1025.7893\n",
      "Epoch 2 completed in 552.57 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_2.pt\n",
      "Training epoch 3/5...\n",
      "Epoch 3/5 Loss: 983.6097\n",
      "Epoch 3 completed in 865.27 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_3.pt\n",
      "Training epoch 4/5...\n",
      "Epoch 4/5 Loss: 963.2624\n",
      "Epoch 4 completed in 1143.16 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_4.pt\n",
      "Training epoch 5/5...\n",
      "Epoch 5/5 Loss: 953.6911\n",
      "Epoch 5 completed in 1307.75 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_5.pt\n",
      "Student Model Size: 0.23 MB\n",
      "Evaluating SimpleProjection Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_coco_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11065/2142845509.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.2254\n"
     ]
    }
   ],
   "source": [
    "# Training function for the student model using DINO with SimpleProjection\n",
    "def train_student_model_dino(\n",
    "    teacher_model, student_model, train_loader, optimizer, \n",
    "    num_epochs=10, checkpoint_dir=None, prefix=None\n",
    "):\n",
    "    epoch_times = []\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    student_model.train()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model features (DINO)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "                teacher_features = teacher_outputs[\"features\"].mean(dim=1)  # Global pooling\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "\n",
    "            # Compute distillation loss (multi-label classification)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(student_logits, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f}\")\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.\")\n",
    "\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss, checkpoint_dir, prefix)\n",
    "            \n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "    return epoch_times\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_student_model_dino(student_model, teacher_model, val_loader, checkpoint_dir=None, prefix=None):\n",
    "    if checkpoint_dir and prefix:\n",
    "        print(f\"Searching for checkpoints in {checkpoint_dir}...\")\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    student_model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model features (DINO)\n",
    "            teacher_outputs = teacher_model(images)\n",
    "            teacher_features = teacher_outputs[\"features\"].mean(dim=1)  # Global pooling\n",
    "\n",
    "            # Student model logits\n",
    "            student_logits = student_model(teacher_features)\n",
    "            predictions = torch.sigmoid(student_logits) > 0.5  # Multi-label thresholding\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute multi-label accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        [tuple(map(int, x)) for x in all_labels], [tuple(map(int, x)) for x in all_predictions]\n",
    "    )\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Main Code to Train and Evaluate\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize SimpleProjection Student Model\n",
    "print(\"Initializing SimpleProjection Student Model...\")\n",
    "teacher_output_dim = 768  # Output dimension of DINO teacher\n",
    "student_output_dim = 256  # Dimension of student model bottleneck\n",
    "num_classes = 80          # Number of COCO categories\n",
    "student_model = SimpleProjectionModel(vision_dim=teacher_output_dim, num_classes=num_classes)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4)\n",
    "\n",
    "# Load DINO Teacher Model\n",
    "print(\"Loading DINO Teacher Model...\")\n",
    "dino_teacher_model = vit_b_16(weights=\"IMAGENET1K_V1\").to('cuda')\n",
    "dino_teacher_model = create_feature_extractor(dino_teacher_model, return_nodes={\"encoder.layers\": \"features\"})\n",
    "\n",
    "# Load the latest checkpoint if it exists\n",
    "prefix = \"simpleprojection_dino_coco_epoch_\"\n",
    "\n",
    "# Train the student model\n",
    "print(\"Training SimpleProjection Student Model...\")\n",
    "epoch_times = train_student_model_dino(\n",
    "    teacher_model=dino_teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=5,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating SimpleProjection Student Model...\")\n",
    "evaluate_student_model_dino(\n",
    "    student_model=student_model,\n",
    "    teacher_model=dino_teacher_model,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abc8e6-449e-485f-bc0e-9eff4a31eb5c",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d8f258-3d2a-41fd-9946-a0c21ba2cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SimpleProjection Student Model...\n",
      "Loading DINO Teacher Model...\n",
      "Training SimpleProjection Student Model...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_coco_epoch_8.pt...\n",
      "Resuming training from epoch 8.\n",
      "Training epoch 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5350/3200071927.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Loss: 951.9704\n",
      "Epoch 9 completed in 1304.23 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_9.pt\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 951.9878\n",
      "Epoch 10 completed in 1300.92 seconds.\n",
      "Checkpoint saved at ./checkpoints/simpleprojection_dino_coco_epoch_10.pt\n",
      "Student Model Size: 0.23 MB\n",
      "Evaluating SimpleProjection Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/simpleprojection_dino_coco_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5350/1872739368.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.2254\n"
     ]
    }
   ],
   "source": [
    "# Train the student model\n",
    "print(\"Training SimpleProjection Student Model...\")\n",
    "epoch_times = train_student_model_dino(\n",
    "    teacher_model=dino_teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "print(\"Evaluating SimpleProjection Student Model...\")\n",
    "evaluate_student_model_dino(\n",
    "    student_model=student_model,\n",
    "    teacher_model=dino_teacher_model,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51157c68-c6be-4084-ae3f-7aa7323cc224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
