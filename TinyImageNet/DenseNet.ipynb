{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb790c76-06d7-4a57-b370-59ea6772c8eb",
   "metadata": {},
   "source": [
    "<h1>Tiny ImageNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e120dcd-3733-4b06-9223-2c75b2586a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Tiny ImageNet data loaders...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, vit_b_16, ViT_B_16_Weights\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "        \n",
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 ** 2)\n",
    "\n",
    "def init_tiny_imagenet_data(data_dir, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir = os.path.join(data_dir, \"val/images\")\n",
    "\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Initialize data loaders\n",
    "print(\"Initializing Tiny ImageNet data loaders...\")\n",
    "tiny_imagenet_dir = \"./data/tiny-imagenet-200\"\n",
    "train_loader, val_loader = init_tiny_imagenet_data(tiny_imagenet_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b666d-7bcc-4228-847e-e05831dade6e",
   "metadata": {},
   "source": [
    "<h2>BEiT</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d1839-2371-4e8b-8ac8-732219dfb790",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c99ec2-f456-449f-8b75-4fedbe6e10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model outputs\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "                teacher_logits = teacher_outputs.pooler_output\n",
    "\n",
    "            # Student model outputs\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss / len(train_loader), checkpoint_dir, prefix)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ca7f8b-7673-473c-8ea0-1942f5106280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_student_model(student_model, teacher_model, val_loader, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    student_model.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Load from checkpoint if specified\n",
    "    if checkpoint_dir and prefix:\n",
    "        print(f\"Searching for checkpoints in {checkpoint_dir}...\")\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Student model outputs\n",
    "            student_logits = student_model(images)\n",
    "            predictions = torch.argmax(student_logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e3f2624-5de5-45d5-897e-0b9238c8c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BEiT Teacher Model...\n",
      "Initializing DenseNet Student Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yx3493/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DenseNet Student Model...\n",
      "Loading checkpoint from ./checkpoints/densenet_beit_epoch_2.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/2663921097.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 2.\n",
      "Training epoch 3/5...\n",
      "Epoch 3/5 Loss: 0.9053\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_3.pt\n",
      "Training epoch 4/5...\n",
      "Epoch 4/5 Loss: 0.7009\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_4.pt\n",
      "Training epoch 5/5...\n",
      "Epoch 5/5 Loss: 0.5520\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_5.pt\n",
      "Training complete.\n",
      "Student Model Size: 27.31 MB\n",
      "Evaluating DenseNet Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/densenet_beit_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/757257291.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.7470\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from transformers import BeitModel\n",
    "\n",
    "# Initialize BEiT Teacher Model\n",
    "print(\"Initializing BEiT Teacher Model...\")\n",
    "beit_teacher_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "# Initialize Student Model\n",
    "print(\"Initializing DenseNet Student Model...\")\n",
    "num_classes = 200\n",
    "student_model = densenet121(pretrained=True)\n",
    "in_features = student_model.classifier.in_features\n",
    "student_model.classifier = torch.nn.Linear(in_features, num_classes)\n",
    "\n",
    "prefix = \"densenet_beit_epoch_\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training\n",
    "print(\"Training DenseNet Student Model...\")\n",
    "train_student_model(beit_teacher_model, student_model, train_loader, optimizer, 5, checkpoint_dir, prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating DenseNet Student Model...\")\n",
    "evaluate_student_model(student_model, beit_teacher_model, val_loader, checkpoint_dir, prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bfb2f4-16d8-4c29-a873-99c59cd0910c",
   "metadata": {},
   "source": [
    "<h4>10 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24505198-ab4c-4882-b02b-3f8e5c76a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DenseNet Student Model...\n",
      "Loading checkpoint from ./checkpoints/densenet_beit_epoch_5.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/2663921097.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 5.\n",
      "Training epoch 6/10...\n",
      "Epoch 6/10 Loss: 0.4395\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_6.pt\n",
      "Training epoch 7/10...\n",
      "Epoch 7/10 Loss: 0.3513\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_7.pt\n",
      "Training epoch 8/10...\n",
      "Epoch 8/10 Loss: 0.2849\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_8.pt\n",
      "Training epoch 9/10...\n",
      "Epoch 9/10 Loss: 0.2319\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_9.pt\n",
      "Training epoch 10/10...\n",
      "Epoch 10/10 Loss: 0.1983\n",
      "Checkpoint saved at ./checkpoints/densenet_beit_epoch_10.pt\n",
      "Training complete.\n",
      "Student Model Size: 27.31 MB\n",
      "Evaluating DenseNet Student Model...\n",
      "Searching for checkpoints in ./checkpoints...\n",
      "Loading checkpoint from ./checkpoints/densenet_beit_epoch_10.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5406/757257291.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.7402\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print(\"Training DenseNet Student Model...\")\n",
    "train_student_model(beit_teacher_model, student_model, train_loader, optimizer, 10, checkpoint_dir, prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating DenseNet Student Model...\")\n",
    "evaluate_student_model(student_model, beit_teacher_model, val_loader, checkpoint_dir, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54430722-7879-4b49-a095-3f760d6dd92a",
   "metadata": {},
   "source": [
    "<h2>DINO - OUT OF CUDA MEMORY</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a68774-7e2f-4c69-906a-820317120f9d",
   "metadata": {},
   "source": [
    "<h4>5 epochs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8091691-44e5-4ee7-8e0f-51332951d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(student_model, optimizer, epoch, loss, checkpoint_dir, prefix):\n",
    "    if checkpoint_dir and prefix:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix}{epoch + 1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': student_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, prefix, student_model, optimizer):\n",
    "    start_epoch = 0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "\n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint_files = [\n",
    "            f for f in os.listdir(checkpoint_dir) if f.startswith(prefix) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if checkpoint_files:\n",
    "            latest_checkpoint = max(\n",
    "                checkpoint_files,\n",
    "                key=lambda x: int(x[len(prefix):-3])\n",
    "            )\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "            print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            print(f\"Resuming training from epoch {start_epoch}.\")\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "def compute_model_size(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 ** 2)\n",
    "\n",
    "\n",
    "def init_tiny_imagenet_data(data_dir, batch_size=32):\n",
    "    transform = Compose([\n",
    "        Resize((384, 384)),  # Match DINO's input size\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir = os.path.join(data_dir, \"val/images\")\n",
    "\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_student_model(teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=None, prefix=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "\n",
    "    start_epoch = 0\n",
    "    if checkpoint_dir and prefix:\n",
    "        start_epoch = load_checkpoint(checkpoint_dir, prefix, student_model, optimizer)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Training epoch {epoch + 1}/{num_epochs}...\")\n",
    "        epoch_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher outputs\n",
    "            with torch.no_grad():\n",
    "                teacher_features = teacher_model(images)  # DINO ViT outputs [batch_size, hidden_dim]\n",
    "                teacher_logits = teacher_features.mean(dim=1)  # Global average pooling for class representation\n",
    "\n",
    "            # Student outputs\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Classification loss\n",
    "            loss = nn.CrossEntropyLoss()(student_logits, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "        print(f\"Epoch {epoch + 1} completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        if checkpoint_dir and prefix:\n",
    "            save_checkpoint(student_model, optimizer, epoch, epoch_loss / len(train_loader), checkpoint_dir, prefix)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Student Model Size: {compute_model_size(student_model):.2f} MB\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_student_model(student_model, val_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model.to(device)\n",
    "    student_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = student_model(images)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Main Code\n",
    "print(\"Initializing Tiny ImageNet data loaders...\")\n",
    "tiny_imagenet_dir = \"./data/tiny-imagenet-200\"\n",
    "train_loader, val_loader = init_tiny_imagenet_data(tiny_imagenet_dir, batch_size=16)\n",
    "\n",
    "# Initialize Teacher and Student Models\n",
    "print(\"Initializing DINO Teacher Model...\")\n",
    "dino_weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "dino_teacher_model = vit_b_16(weights=dino_weights).eval()\n",
    "dino_teacher_model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "\n",
    "print(\"Initializing DenseNet Student Model...\")\n",
    "student_model = densenet121(pretrained=True)\n",
    "\n",
    "in_features = student_model.classifier.in_features\n",
    "student_model.classifier = nn.Linear(in_features, 200)\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "student_model.features = checkpoint_sequential(student_model.features, segments=4)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-4)\n",
    "\n",
    "# Training\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "prefix = \"densenet_dino_epoch_\"\n",
    "\n",
    "print(\"Training Student Model...\")\n",
    "train_student_model(dino_teacher_model, student_model, train_loader, optimizer, num_epochs=5, checkpoint_dir=checkpoint_dir, prefix=prefix)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating Student Model...\")\n",
    "evaluate_student_model(student_model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b6b7d-6f72-405a-923d-6b994bfa3de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
